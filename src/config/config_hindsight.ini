[env]
size = 5
min_qbit_err = 1
p_error = 0.02
p_msmt = 0.00
stack_depth = 8
error_channel = iidxz
max_actions = 128
state_multiplier = 20
terminal_action = 4

[general]
summary_path = testing
summary_date = eval
summary_run_info = summary_run_info


[hindsight]
num_cuda = 0
num_cpu = 3
num_environments = 3
size_local_memory_buffer = 1000
verbosity = 2
benchmarking = 0
epsilon = 0.8
load_model = 0
discount_intermediate_reward = 0.3
min_value_factor_intermediate_reward = 0.0
decay_factor_intermediate_reward = 0.999997
decay_factor_epsilon = 0.99997
min_value_factor_epsilon = 0.0
update_every = 1000
n_episodes = 100000
epoch_steps = 100000
size_action_history = 10000
learning_rate = 0.01
tau = 0.2
discount_factor = 0.9998
device = "cpu"
id = 1105
n = 4
load_model = 0


[replay_buffer]
buffer_size = 10000
batch_size = 64
n_step = 1

[learner]
verbosity = 4
benchmarking = 0
max_time_h = 10
max_time_minutes = 0
learning_rate = 1e-3
device = cpu
target_update_steps = 200
discount_factor = 0.95
learner_epsilon = 0.0
batch_size = 8
eval_frequency = 25
max_timesteps = 1000000
model_name = Conv3DEvolvedAgent
model_config_file = conv_agents_3d_evolved.json
model_config_location = src/config/model_spec/
load_model = 0
#load_model_path = networks/
save_model_path = networks

[rewards]
non_trivial_loop = -39
syndrome_left = -19
solved_episode = 100
syndrome_difference = 0.2
repeating_action = 0