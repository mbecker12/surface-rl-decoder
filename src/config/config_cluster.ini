[env]
size=3
min_qbit_err=0
p_error=0.02
p_msmt=0.00
stack_depth=8
error_channel=dp
max_actions=128
state_multiplier=1
terminal_action=4

[general]
summary_path=runs
summary_date=gputest
summary_run_info=run_info
description=

[actor]
num_cuda=4
num_cpu=0
num_environments=64
size_local_memory_buffer=1000
verbosity=2
benchmarking=0
epsilon=0.8
load_model=0
discount_intermediate_reward=0.3
min_value_factor_intermediate_reward=0.0
decay_factor_intermediate_reward=0.99999
decay_factor_epsilon=0.99999
min_value_factor_epsilon=0.01

[replay_memory]
size=1000000
replay_size_before_sampling=2000
verbosity=2
benchmarking=0
memory_type=prio
alpha=0.9
beta=0.4
decay_beta=1.000015
nvidia_log_frequency=15

;ppo
episode_buffer_tau=0.97
max_buffer_episodes=10000
max_buffer_episode_steps=25
episode_buffer_device=cpu

[learner]
verbosity=4
benchmarking=0
; hours
max_time_h=12
; minutes
max_time_minutes=0
learning_rate=1e-3
device=cuda
target_update_steps=200
discount_factor=0.95
learner_epsilon=0.0
batch_size=256
eval_frequency=250
max_timesteps=1000000
;model_name=dummy_agent
;model_config_file=dummy_agent.json
model_name=conv2d_lstm
model_config_file=conv_agents.json
model_config_location=src/config/model_spec/
load_model=0
load_model_path=networks/test13/dummy_agent_5_test13.pt
save_model_path=networks

;ppo
policy_model_max_grad_norm=10000
policy_clip_range=0.1
policy_stopping_kl=0.02
value_model_max_grad_norm=10000
value_clip_range=100
value_stopping_mse=25
entropy_loss_weight=0.1
value_loss_weight=0.9
max_episodes=1024
optimization_epochs=100

[reward]
non_trivial_loop=-39
syndrome_left=-19
solved_episode=100
syndrome_difference=5
repeating_action=0
