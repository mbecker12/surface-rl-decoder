[env]
size=5
min_qbit_err=0
p_error=0.02
p_msmt=0.00
stack_depth=8
error_channel=dp
max_actions=64
state_multiplier=1
terminal_action=4

[general]
summary_path=runs
summary_date=gputest
summary_run_info=run_info
description=

[actor]
num_cuda=4
num_cpu=0
num_environments=128
size_local_memory_buffer=2000
verbosity=2
benchmarking=0
epsilon=0.8
load_model=0
discount_intermediate_reward=0.3
min_value_factor_intermediate_reward=0.0
decay_factor_intermediate_reward=0.99998
decay_factor_epsilon=0.99998
min_value_factor_epsilon=0.02

[replay_memory]
size=8388608
replay_size_before_sampling=2000
verbosity=2
benchmarking=0
memory_type=prio
alpha=0.9
beta=0.4
decay_beta=1.000013
nvidia_log_frequency=30

;ppo
episode_buffer_tau=0.97
max_buffer_episodes=10000
max_buffer_episode_steps=32
episode_buffer_device=cpu

[learner]
verbosity=5
benchmarking=0
; hours
max_time_h=6
; minutes
max_time_minutes=0
learning_rate=1e-3
device=cuda
target_update_steps=200
discount_factor=0.95
learner_epsilon=0.0
batch_size=256
eval_frequency=250
max_timesteps=1000000
;model_name=dummy_agent
;model_config_file=dummy_agent.json
model_name=conv3d
model_config_file=conv_agents.json
model_config_location=custom_config/
load_model=0
load_model_path=networks/test13/dummy_agent_5_test13.pt
save_model_path=networks

;ppo
policy_model_max_grad_norm=100
policy_clip_range=0.1
policy_stopping_kl=0.02
value_model_max_grad_norm=100
value_clip_range=1
value_stopping_mse=25
entropy_loss_weight=0.01
value_loss_weight=0.0001
max_episodes=1024
optimization_epochs=100

[reward]
non_trivial_loop=-39
syndrome_left=-19
solved_episode=100
syndrome_difference=5
repeating_action=0
